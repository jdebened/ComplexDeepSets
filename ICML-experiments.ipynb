{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf # NOTE: This code runs with tensorflow version 2.0.0\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, GRU, Embedding, Lambda, concatenate, multiply, add\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tqdm import tqdm,trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_examples = 100000\n",
    "max_train_length = 50\n",
    "\n",
    "num_test_examples = 10000\n",
    "min_test_length=5\n",
    "max_test_length=100\n",
    "step_test_length=5\n",
    "losstype='mse'\n",
    "\n",
    "lengths = range(min_test_length, max_test_length, step_test_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some data functions, not needed if loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_data(num_train_examples, max_train_length):\n",
    "    X = np.zeros((num_train_examples,100))\n",
    "    sum_X = np.zeros((num_train_examples))\n",
    "    for i in tqdm(range(num_train_examples), desc='Generating train examples: '):\n",
    "        n = np.random.randint(1,max_train_length)\n",
    "        for j in range(1,n+1):\n",
    "            X[i,-j] = np.random.randint(1,10)\n",
    "        sum_X[i] = np.sum(X[i])\n",
    "    return X, sum_X\n",
    "\n",
    "def gen_test_data(num_examples, length):\n",
    "    Y = np.zeros((num_examples, max_test_length))\n",
    "    sum_Y = np.zeros((num_examples))\n",
    "    for i in range(num_examples):\n",
    "        for j in range(1,length+1):\n",
    "            Y[i,-j] = np.random.randint(1,10)\n",
    "        sum_Y[i] = np.sum(Y[i])\n",
    "    return Y, sum_Y\n",
    "\n",
    "def gen_test_lengths(num_test_examples):\n",
    "    lengths = range(min_test_length, max_test_length, step_test_length)\n",
    "    testY = {}\n",
    "    testSumY = {}\n",
    "    for l in lengths:    \n",
    "        # generate test data\n",
    "        Y, sum_Y = gen_test_data(num_test_examples, l)\n",
    "        testY[l] = Y\n",
    "        testSumY[l] = sum_Y\n",
    "    return testY, testSumY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can either generate and save or load existing\n",
    "gen = True\n",
    "if gen:\n",
    "    # If we want to generate and save the training and test sets\n",
    "    X, sum_X = gen_train_data(num_train_examples, max_train_length)\n",
    "    testY, testSumY = gen_test_lengths(num_test_examples)\n",
    "    metrics = {}\n",
    "    allPreds = {}\n",
    "    if False:\n",
    "        np.save(\"data/X\",X)\n",
    "        np.save(\"data/sum_X\",sum_X)\n",
    "        np.save(\"data/testY\",testY)\n",
    "        np.save(\"data/testSumY\",testSumY)\n",
    "        np.save(\"data/metrics\",metrics)\n",
    "        np.save(\"data/allPreds\",allPreds)    \n",
    "else:\n",
    "    X = np.load(\"data/X.npy\")\n",
    "    sum_X = np.load(\"data/sum_X.npy\")\n",
    "    testY = np.load(\"data/testY.npy\",allow_pickle=True)\n",
    "    testSumY = np.load(\"data/testSumY.npy\",allow_pickle=True)\n",
    "    metrics = np.load(\"data/metrics.npy\",allow_pickle=True)\n",
    "    allPreds = np.load(\"data/allPreds.npy\",allow_pickle=True)\n",
    "    testY = testY[()]\n",
    "    testSumY = testSumY[()]\n",
    "    metrics = metrics[()]\n",
    "    allPreds = allPreds[()]\n",
    "    \n",
    "\n",
    "orig_sum_X = sum_X\n",
    "orig_testSumY = testSumY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change to problem of outputting the ones digit only, do this\n",
    "sum_X = [x%10 for x in orig_sum_X]\n",
    "testSumY = {x: [y%10 for y in orig_testSumY[x]] for x in orig_testSumY}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x, mask):\n",
    "    # Handles masking\n",
    "    if K.is_keras_tensor(mask):\n",
    "        mask_cast = K.cast(mask, 'float32')\n",
    "        expanded = K.expand_dims(mask_cast)\n",
    "        return K.sum(expanded * x, axis=1)\n",
    "    return K.sum(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeModel(model):\n",
    "    display(SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg')))\n",
    "    return None\n",
    "\n",
    "def trainModel(model,numEpochs=200,trainData=X,trainWeights=sum_X):\n",
    "    # train\n",
    "    earlyStop = EarlyStopping(monitor='val_loss',patience=10,verbose=1,min_delta=0.00001)\n",
    "    lrscheduler = ReduceLROnPlateau(monitor='val_loss',patience=2,factor=0.5,verbose=1,min_delta=0.0001,cooldown=3)\n",
    "    \n",
    "    model.fit(X, sum_X, epochs=numEpochs, batch_size=128,\n",
    "            shuffle=True, validation_split=0.0123456789,\n",
    "            callbacks=[earlyStop,lrscheduler])\n",
    "\n",
    "    temp_we = {}\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        w = layer.get_weights()\n",
    "        temp_we[idx] = w\n",
    "\n",
    "    preds = model.predict(X, batch_size=128, verbose=1)\n",
    "    print(\"Training accuracy:\", 1.0*np.sum(np.squeeze(np.round(preds))==sum_X)/len(sum_X))\n",
    "    print(\"Mean absolute error:\", np.sum(np.abs(np.squeeze(preds)-sum_X))/len(sum_X))\n",
    "    \n",
    "    return temp_we\n",
    "\n",
    "def loadModel(model, modelWeights):\n",
    "    # load weights\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        w = modelWeights[idx]\n",
    "        layer.set_weights(w)\n",
    "    return model\n",
    "\n",
    "def evaluateModel(modelFunc, modelWeights, name):\n",
    "    metrics[name] = {'acc':[], 'mae':[], 'mse':[]}\n",
    "    allPreds[name] = {}\n",
    "    for l in lengths:\n",
    "        print('Evaluating at length: ', l)\n",
    "        K.clear_session()\n",
    "\n",
    "        # Retrieve test data\n",
    "        Y = testY[l]\n",
    "        sum_Y = testSumY[l]\n",
    "\n",
    "        # model\n",
    "        model = modelFunc(max_test_length)\n",
    "        model = loadModel(model, modelWeights)\n",
    "\n",
    "        # prediction\n",
    "        preds = model.predict(Y, batch_size=128, verbose=0)\n",
    "        allPreds[name][l] = preds\n",
    "        metrics[name]['acc'].append(1.0*np.sum(np.squeeze(np.round(preds))==sum_Y)/len(sum_Y))\n",
    "        metrics[name]['mae'].append(np.sum(np.abs(np.squeeze(preds)-sum_Y))/len(sum_Y))\n",
    "        metrics[name]['mse'].append(np.dot(np.squeeze(preds)-sum_Y, np.squeeze(preds)-sum_Y)/len(sum_Y))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code comes from the DeepSets repository but is modified to include masking in the Lambda layer\n",
    "def get_deepset_model(max_length):\n",
    "    input_txt = Input(shape=(max_length,))\n",
    "    x = Embedding(11, 100, mask_zero=True)(input_txt)\n",
    "    x = Dense(30, activation='tanh')(x)\n",
    "    # we don't want to pass the mask, we want to use it before applying the sum though\n",
    "    Adder = Lambda(fun, output_shape=lambda s: (s[0], s[2]), )\n",
    "    x = Adder(x)\n",
    "    encoded = Dense(1)(x)\n",
    "    summer = Model(input_txt, encoded)\n",
    "    adam = Adam(lr=1e-4, epsilon=1e-3)\n",
    "    summer.compile(optimizer=adam, loss=losstype)\n",
    "    return summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Deepset model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = get_deepset_model(100)\n",
    "deep_mse_we = trainModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Deepsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluateModel(get_deepset_model, deep_mse_we, \"DeepSets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equal Parameter Deepsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified DeepSets model to match our number of parameters\n",
    "def get_ep_model(max_length):\n",
    "    input_txt = Input(shape=(max_length,))\n",
    "    x = Embedding(11, 150, mask_zero=True)(input_txt)\n",
    "    # we don't want to pass the mask, we want to use it before applying the sum though\n",
    "    Adder = Lambda(fun, output_shape=lambda s: (s[0], s[2]), )\n",
    "    x = Adder(x)\n",
    "    encoded = Dense(1)(x)\n",
    "    summer = Model(input_txt, encoded)\n",
    "    adam = Adam(lr=1e-4, epsilon=1e-3)\n",
    "    summer.compile(optimizer=adam, loss=losstype)\n",
    "    return summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = get_ep_model(100)\n",
    "ep_mse_we = trainModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluateModel(get_ep_model, ep_mse_we, \"epDeepSets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM baseline, code from DeepSets repository\n",
    "def get_lstm_model(max_length):\n",
    "    input_txt = Input(shape=(max_length,))\n",
    "    x = Embedding(11, 100, mask_zero=True)(input_txt)\n",
    "    x = LSTM(50)(x)\n",
    "    encoded = Dense(1)(x)\n",
    "    summer = Model(input_txt, encoded)\n",
    "    adam = Adam(lr=1e-4)\n",
    "    summer.compile(optimizer=adam, loss=losstype)\n",
    "    return summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = get_lstm_model(100)\n",
    "lstm_we = trainModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluateModel(get_lstm_model, lstm_we, \"LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU baseline, code from DeepSets repository\n",
    "def get_gru_model(max_length):\n",
    "    input_txt = Input(shape=(max_length,))\n",
    "    x = Embedding(11, 100, mask_zero=True)(input_txt)\n",
    "    x = GRU(80)(x)\n",
    "    encoded = Dense(1)(x)\n",
    "    summer = Model(input_txt, encoded)\n",
    "    adam = Adam(lr=1e-4)\n",
    "    summer.compile(optimizer=adam, loss=losstype)\n",
    "    return summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = get_gru_model(100)\n",
    "gru_we = trainModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluateModel(get_gru_model, gru_we, \"GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save computed metrics and predictions for future reference\n",
    "np.save(\"data/metrics\",metrics)\n",
    "np.save(\"data/allPreds\",allPreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Method (Complex Normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complexNormedMultiply(q, mask):\n",
    "    x = q[0]\n",
    "    y = q[1]\n",
    "    r = q[2]\n",
    "    initX = q[3]\n",
    "    initY = q[4]\n",
    "    initR = q[5]\n",
    "    # Here x is the real part and y is the imaginary part\n",
    "    if tf.is_tensor(mask):\n",
    "        # this sets masked values to 1+0i\n",
    "        mask_cast = K.cast(mask, 'float32')\n",
    "        expanded = K.expand_dims(mask_cast)\n",
    "        zeroX = expanded * x\n",
    "        newY = expanded * y\n",
    "        newR = expanded * r\n",
    "        # here I flip the mask (essentially XOR)\n",
    "        antiMask = tf.ones(expanded.shape)-expanded\n",
    "        newX = zeroX+antiMask\n",
    "    else:\n",
    "        newX = x\n",
    "        newY = y\n",
    "        newR = r\n",
    "    sumVecs = tf.math.sqrt(tf.multiply(newX,newX)+tf.multiply(newY,newY))\n",
    "    normedX = newX/sumVecs\n",
    "    normedY = newY/sumVecs\n",
    "    normedR = newR\n",
    "    initSum = tf.math.sqrt(tf.multiply(initX,initX)+tf.multiply(initY,initY))\n",
    "    inX = initX/initSum\n",
    "    inY = initY/initSum\n",
    "    # Using builtin complex numbers\n",
    "    complexVec = tf.complex(normedX,normedY)\n",
    "    initVec = tf.complex(inX,inY)\n",
    "    complexOut = K.prod(complexVec,axis=1)\n",
    "    newCOut = multiply([complexOut,tf.expand_dims(initVec,0)])\n",
    "    rOut = K.sum(normedR,axis=1)\n",
    "    newROut = add([rOut,tf.expand_dims(initR,0)])\n",
    "    tensorOut = concatenate(list([tf.math.real(newCOut),tf.math.imag(newCOut),newROut]))\n",
    "    return tensorOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normedcartset_model(max_length):\n",
    "    edim = 50\n",
    "    ddim = 15\n",
    "    input_txt = Input(shape=(max_length,))\n",
    "    # We want x to be the real part and y to be the imaginary part and r is the magnitude in a sense\n",
    "    # e^r(x+yi)\n",
    "    x = Embedding(11, edim, mask_zero=True)(input_txt)\n",
    "    y = Embedding(11, edim, mask_zero=True)(input_txt)\n",
    "    r = Embedding(11, edim, mask_zero=True)(input_txt)\n",
    "    # the init variables account for lambda*rho\n",
    "    # thus lambda*rho = e^initR(initX+initY)\n",
    "    initX = K.variable(value=np.ones(edim),dtype='float32')\n",
    "    initY = K.variable(value=np.ones(edim),dtype='float32')\n",
    "    initR = K.variable(value=np.ones(edim),dtype='float32')\n",
    "    CM = Lambda(complexNormedMultiply, output_shape=lambda s: (s[0][0], s[0][2]*3), name=\"NormedComplexMultiply\")\n",
    "    z = CM([x,y,r,initX,initY,initR])\n",
    "    encoded = Dense(1)(z)\n",
    "    model = Model(input_txt, encoded)\n",
    "    adam = Adam(lr=1e-4, epsilon=1e-3)\n",
    "    model.compile(optimizer=adam, loss=losstype)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Normed Complex Cartesian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = get_normedcartset_model(100)\n",
    "normedcartset_mse_we = trainModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Normed Complex Cartesian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluateModel(get_normedcartset_model, normedcartset_mse_we, \"Our Method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_deepset_model(max_train_length)\n",
    "print(\"DeepSets model has \" + str(model.count_params()) + \" parameters\")\n",
    "model = get_lstm_model(max_train_length)\n",
    "print(\"LSTM model has \" + str(model.count_params()) + \" parameters\")\n",
    "model = get_gru_model(max_train_length)\n",
    "print(\"GRU model has \" + str(model.count_params()) + \" parameters\")\n",
    "model = get_normedcartset_model(max_train_length)\n",
    "print(\"Our model has \" + str(model.count_params()) + \" parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model=get_normedcartset_model(max_train_length)\n",
    "visualizeModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This code comes mainly from the DeepSets repository, with some modifications\n",
    "font = {'size': 14}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "scale = 1\n",
    "plt.figure(figsize=(10*scale, 8*scale))\n",
    "\n",
    "trainedModels = metrics.keys()\n",
    "legendNames = []\n",
    "spot = 0\n",
    "markers = ['o-','s-','+-','D-','1-','2-','x-']\n",
    "for modName in trainedModels:\n",
    "    legendNames.append(modName)\n",
    "    plt.plot(lengths, metrics[modName]['acc'], markers[spot%7])\n",
    "    spot+=1\n",
    "plt.xlabel('Number of digits')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.ylim( 0, 1.1 )\n",
    "plt.xlim( 5, 95 )\n",
    "plt.legend(legendNames, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size': 14}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "scale = 1\n",
    "plt.figure(figsize=(10*scale, 8*scale))\n",
    "\n",
    "for modName in trainedModels:\n",
    "    plt.plot(lengths, np.array(metrics[modName]['mae'])/1e2, 'x-')\n",
    "plt.xlabel('Number of input digits')\n",
    "plt.ylabel('Mean absolute error/1e2')\n",
    "plt.title('MAE')\n",
    "plt.legend(legendNames, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size': 14}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "scale = 1\n",
    "plt.figure(figsize=(10*scale, 8*scale))\n",
    "\n",
    "for modName in trainedModels:\n",
    "    plt.plot(lengths, np.array(metrics[modName]['mse']), 'x-')\n",
    "plt.xlabel('Number of input digits')\n",
    "plt.ylabel('Mean squared error')\n",
    "plt.title('MSE')\n",
    "plt.legend(legendNames, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
